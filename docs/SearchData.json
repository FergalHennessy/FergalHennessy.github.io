{"0": {
"doc":  "Merge K Lists",
"title": "Merge K Lists",
"content": "Merge K Lists . You are given an array of k linked-lists lists, where each linked list is sorted in ascending order. merge all the linked-lists into one sorted linked-list and return it . /** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */ . Examples: . lists = [[1, 4, 5], [1, 3, 4], [2, 6]] –&amp;gt; [1,1,2,3,4,4,5,6] lists = [] –&amp;gt; [] lists = [[]] –&amp;gt; [] . Solution 1 : Pairs . Because merging two lists is simple, one intuitive approach could be to merge greedily, merging list 1 with list 2, the result with list 3, and so on. Writing it up quickly, we might get some code that looks like this: . class Solution{ private: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2){ if(l1 == nullptr) return l2; if(l2 == nullptr) return l1; if(l1-&amp;gt;val &amp;lt; l2-&amp;gt;val){ l1-&amp;gt;next = mergeTwoLists(l1-&amp;gt;next, l2); return l1; }else{ l2-&amp;gt;next = mergeTwoLists(l1, l2-&amp;gt;next); return l2; } } public: ListNode* mergeKLists(vector&amp;lt;ListNode*&amp;gt;&amp;amp; lists){ if(lists.empty()) return nullptr; for(int i = 0; i &amp;lt; lists.size() - 1; ++i){ lists[i+1] = mergeTwoLists(lists[i], lists[i+1]); } return lists[lists.size() - 1]; } }; . Runtime Analysis: Assuming k lists with an average size of n, we note that the first merger has 2n comparisons, the second 3n, and so on until the final list has (k+1)n comparisons for a total \\(O(k^2\\*n)\\) runtime . It&#39;s possible to do better with this pairs strategy by using a queue: we can merge lists of the same size and push the resulting bigger list to the back of a queue. Using this strategy, our runtime is O(n*k*log(k)). class Solution{ private: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2){ if(l1 == nullptr) return l2; if(l2 == nullptr) return l1; if(l1-&amp;gt;val &amp;lt; l2-&amp;gt;val){ l1-&amp;gt;next = mergeTwoLists(l1-&amp;gt;next, l2); l1 = l1-&amp;gt;next; }else{ l2-&amp;gt;next = mergeTwoLists(l1, l2-&amp;gt;next)l; l2 = l2-&amp;gt;next; } } public: ListNode* mergeKLists(vector&amp;lt;ListNode*&amp;gt;&amp;amp; lists){ if(lists.size() == 0) return nullptr; for(int i = 0; i + 1 &amp;lt; lists.size(); i+=2){ lsits.push_back(mergeTwoLists(lists[i], lists[i+1])); } return lists[i]; } } . Solution 2 : MinHeap . A different approach to this problem, that ends up having the same asymptotic runtime, uses priority queues instead of simple queues to order the data. The idea behind this solution is placing all the linked lists in a big minHeap, sorted by the first element of each linked list. This way, the linked list node that we are interested in will always be at the top of the heap. We can build a new linked list by popping the least element from the top of the minHeap in a loop, then push the rest of the loop back to the minHeap. class Solution{ ListNode* mergeKLists(vector&amp;lt;ListNode*&amp;gt; lists){ auto compare = [](ListNode* a, ListNode* b){return a-&amp;gt;val &amp;gt; b-&amp;gt;val;}; priority_queue&amp;lt;ListNode*, vector&amp;lt;ListNode*&amp;gt;, decltype(compare)&amp;gt; minHeap(compare); for(list : lists){ if(list)minHeap.push(list); } ListNode dummy = ListNode(0); ListNode* tail = &amp;amp;dummy; while(!minHeap.empty){ //add the least element to tail tail-&amp;gt;next = minHeap.top(); minHeap.pop(); tail = tail-&amp;gt;next; //push the remaining list back to the heap if(tail-&amp;gt;next) minHeap.push(tail-&amp;gt;next); } return dummy.next; } } . Runtime Analysis: As above, assuming k lists with n members per list, the initial building of the minHeap takes O(k* log(k)) time. When building our solution linked list, we have n*k insertions, each of which takes O(log(k)) time, giving us an asymptotic runtime of O(n * k * log(k)), the same as above.",
"url": "/docs/note/Merge-K-Lists"
},"1": {
"doc":  "Longest Valid Parentheses",
"title": "Longest Valid Parentheses",
"content": "Longest Valid Parentheses . You are given a string s containing just the characters &#39;(&#39; and &#39;)&#39;. return the length of the longest valid (well-formed) parentheses substring . Examples . Input =&quot; (()&quot; –&amp;gt; 2 Input = &quot;)()())&quot; –&amp;gt; 4 Input = &quot;&quot; –&amp;gt; 0 . Solution 1: . Noting that computing the longest substring at any given point in the string requires memory of previous longest substrings, we decide to use dynamic programming. We can determine the longest substring at the ith index with the following recurrence relations: . | If (s[i] == &#39;(&#39;) longest = 0 | if (s[i] == &#39;)&#39; &amp;amp;&amp;amp; s[i-1] == &#39;(&#39;) longest = dp[i-2] + 2 | if (s[i] == &#39;)&#39; &amp;amp;&amp;amp; s[i - s[i-1] -1] == &#39;(&#39;) longest = dp[i-1] + dp[i-dp[i-1] - 2] + 2 | . where equation 3 uses the previously computed longest strings to determine whether a large containing set of parentheses exists . Using these recurrence equations, dynamic programming, and some safeguards to out of bounds errors, we write the following code: . class Solution{ public: int longestValidParentheses(string s){ int dp[s.size()]; int res = 0; for(int i = 0; i &amp;lt; s.size(); ++i){ if(s[i] == &#39;(&#39;) dp[i] = 0; else if(s[i] == &#39;)&#39; &amp;amp;&amp;amp; i &amp;gt; 0 &amp;amp;&amp;amp; s[i-1] == &#39;(&#39;) dp[i] = (i-2 &amp;gt;= 0 ? dp[i-2] : 0) + 2; else if(s[i] == &#39;)&#39; &amp;amp;&amp;amp; i &amp;gt; 0 &amp;amp;&amp;amp; dp[i-1] + 1 &amp;lt;= i &amp;amp;&amp;amp; s[i-dp[i-1]-1] == &#39;(&#39;) dp[i] = dp[i-1] + (i - dp[i-1] - 2 &amp;gt;= 0 ? dp[i-dp[i-1]-2] : 0) + 2; else dp[i] = 0; res = max(res, dp[i]); } return res; } }; . Solution 2: . Noting that, generally speaking, we need to store only the indexes of most recent open parentheses and any orphan close parentheses that break up substrings, it looks like we can use a stack for this problem. In general, there are three cases: . | If str[i] == &#39;(&#39; push i to stack | if str[i] == &#39;)&#39; &amp;amp;&amp;amp; s[stack.top] == &#39;(&#39; pop from stack | else push i to stack (s[i] is an orphan) | . Afterwards, if the stack is not empty, we pop from stack and return the longest sequence. Adding some edge cases and then typing this up, we obtain . class Solution{ public: int longestValidParentheses(string s){ stack&amp;lt;int&amp;gt; st; int res = 0; for(int i = 0; i &amp;lt; s.size(); ++i){ if(s[i] == &#39;(&#39;) st.push(i); else if(s[i] == &#39;)&#39; &amp;amp;&amp;amp; !st.empty() &amp;amp;&amp;amp; s[st.top()] == &#39;(&#39;) st.pop(); else st.push(i); } if(st.empty()) return s.size(); st.push(s.size()); while(!st.empty()){ int curr = st.top(); st.pop(); if(!st.empty()) res = max(res, curr - st.top() - 1); else{res = max(curr, res);} } return res; } }; .",
"url": "/docs/note/Longest-Valid-Parentheses"
},"2": {
"doc":  "LeetCode Problems",
"title": "LeetCode Problems",
"content": "LeetCode Problems! . LC 23: [[Merge K Lists]] . LC 25: [[Reverse Nodes In K-Group]] . LC 32: [[Longest Valid Parentheses]] .",
"url": "/docs/note/LeetCode-Problems"
},"3": {
"doc":  "Reverse Nodes In K-Group",
"title": "Reverse Nodes In K-Group",
"content": "Reverse Nodes In K-Group . Given the head of a linked list, reverse the nodes of the list k at a time, without altering the value of any nodes in the list. If the number of nodes is not a multiple of k then left-out nodes, in the end, should remain as it is. Return the modified list. /** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */ . Examples . Input: {head = [1, 2, 3, 4, 5], k = 2} –&amp;gt; [2, 1, 3, 4, 5] Input: {head = [1, 2, 3, 4, 5], k = 3} –&amp;gt; [3, 2, 1, 4, 5] Input: {head = [1, 2], k= 2} –&amp;gt; [2, 1] . Solution 1: Recursion . To quickly tackle this problem, recursion makes a lot of sense, as the back of the list can be transformed independently of earlier items. To implement a recursion solution takes three steps: . | Look Ahead: define a pointer cursor which looks ahead to see if we have enough space to do a reversal (if we have k or more nodes in the current list) . | List Reversal: similar to normal linked-list reversal, but limited to k items. Use 3 ListNode* variables: curr, nxt, and prev. | Recursive Call: set the next item in the list to the result of a new reversal call, and return the head of the current list . | . Coding this up, we find the following function: . ListNode* reverseKGroup(ListNode* head, int k){ ListNode* cursor = head; for(int i = 0; i&amp;lt;k; ++i){ if(cursor == nullptr) return head; cursor = cursor-&amp;gt;next; } ListNode* curr = head; ListNode* prev = nullptr; ListNode* nxt = nullptr; for(int i = 0; i &amp;lt; k; ++i){ nxt = curr-&amp;gt;next; curr-&amp;gt;next = prev; prev = curr; curr = nxt; } head-&amp;gt;next = reverseKGroup(curr, k); return prev; } . Runtime Analysis: The runtime of this function is O(n), as each node is traversed at most twice. The space complexity of this function is O(n) due to call stacks and its recursive nature. This function is easy to understand as is, but to reduce the space complexity we can rewrite it to be iterative. Solution 2: Iteration . ListNode* reverseKGroup(ListNode* head, int k) { ListNode* dummy = new ListNode(0); dummy-&amp;gt;next = head; ListNode* before = dummy; ListNode* after = head; ListNode* curr = nullptr; ListNode* prev = nullptr; ListNode* nxt = nullptr; while(true){ ListNode* cursor = after; for(int i = 0; i &amp;lt; k; i++){ if(cursor == nullptr) return dummy-&amp;gt;next; cursor = cursor-&amp;gt;next; } curr = after; prev = before; for(int i = 0; i &amp;lt; k; i++){ nxt = curr-&amp;gt;next; curr-&amp;gt;next = prev; prev = curr; curr = nxt; } after-&amp;gt;next = curr; before-&amp;gt;next = prev; before = after; after = curr; } } .",
"url": "/docs/note/Reverse-Nodes-In-K-Group"
},"4": {
"doc":  "Substring With Concatenation Of All Words",
"title": "Substring With Concatenation Of All Words",
"content": "Substring With Concatenation Of All Words . You are given a string s, and an array of strings words. All the strings of words are of the same length . A concatenated substring in s is a substring that contains all the strings of any permutation of words concatenated. Essentially, if all the words in words appear exactly once consecutively, then the substring is a concatenated substring. Return the starting indices of the concatenated substrings in s. You can return the answer in any order. Examples . Input:s = &quot;barfoothefoobarman&quot;, words = [&quot;foo, bar&quot;] –&amp;gt; [0, 9] Input: s = &quot;wordgoodgoodgoodbestword&quot;, words = [&quot;word&quot;, &quot;good&quot;, &quot;best&quot;, &quot;word&quot;] –&amp;gt; [] . Solution 1: Brute Force Hashmap Comparison . Let the size of s be n, let the number of elements in words be m, let the length of a word in words be w. It follows that every concatenated substring will have length m * w. We can brute force a solution as follows: . | load all words into a hashmap total | For each length m * w substring of s, split into length w pieces, add the pieces to a new hashmap prospect and check prospect == total | Return a vector of all the indices where step 2 is true. Putting these steps into code, we get this solution: | . class Solution{ public: vector&amp;lt;int&amp;gt; findSubstring(string s, vector&amp;lt;string&amp;gt;&amp;amp; words){ vector&amp;lt;int&amp;gt; res; if(words.size() == 0) return res; unordered_map&amp;lt;string, int&amp;gt; total; for(string&amp;amp; word: words){ total[word]++; } int m = words.size(); int w = words[0].size(); for(int i = 0; i &amp;lt; s.size() - (m*w) + 1; ++i){ unordered_map&amp;lt;string, int&amp;gt; prospect; int j = i; while(j &amp;lt; i + (m*w)){ string word = s.substr(j, w); prospect[word] += 1; j+= w; } if(prospect == total) res.push_back(i); } return res; } }; . Runtime Analysis: . | Building total: O(1) * m = O(m) | Building prospect and comparing with total: O(m*w) (There are (m*w) characters in both maps) | Iterating through s: O(n) Total Runtime: O(m) + O(n * m * w) = O(n * m* w) | . Space Analysis: . | total: O(m*w) | prospect: O(m*w) (n times) Space complexity is also O(m*n*w) | . Both space and time are cubic: can we do better? Looking at this solution, we do a lot of duplicate comparisons. if we create a map prospect and check all the internals against total, then discard it, we waste a lot of comparisons that we could have saved for future iterations… . Solution 2: Sliding Window Hashmap Comparison . We can use a sliding window approach to avoid duplicate comparisons. As before, let the size of s be n, let the number of elements in words be m, let the length of a word in words be w. Because hashmaps can only be recycled when the next hashmap begins a multiple of w away, we will need an outer loop of size n. Our solution has three steps: . | Create a hashmap (total) of all strings in words, with higher values corresponding to more occurrences | Loop through all possible remainders (mod w). In each iteration: . | create a new hashmap prospect, and a new string t | Create a loop of length n to loop through the characters in s. In each iteration: . | increment t until it is length w, then add t to prospect | when your window size has reached the size of a concatenated string, check whether prospect == total. If it does, save the start of the window. | . | . | return the list of valid starting indices | . Coding this up: . class Solution{ public: vector&amp;lt;int&amp;gt; findSubstring(string s, vector&amp;lt;string&amp;gt;&amp;amp; words){ int n = s.size(); int m = words.size(), w = words[0].size(); unordered_map&amp;lt;string, int&amp;gt; total; for(string&amp;amp; word : words){ total[word]++; } vector&amp;lt;int&amp;gt; res; for(int i = 0; i &amp;lt; w; i++){ unordered_map&amp;lt;string, int&amp;gt; prospect; string t = &quot;&quot;; for(int j = i, k = i; k &amp;lt; n; k++){ t += s[k]; if(t.size() == w){ prospect[t]++; t = &quot;&quot;; } if(k-j+1 == m*w){ if(prospect == total)res.push_back(j); string remove = s.substr(j, w); if(prospect[remove] &amp;gt; 1) prospect[remove]--; else prospect.erase(remove); j+=w; } } } return res; } }; .",
"url": "/docs/note/Substring-With-Concatenation-Of-All-Words"
},"5": {
"doc":  "Candy (Peaks and Valleys)",
"title": "Candy (Peaks and Valleys)",
"content": "Candy . There are n children standing in a line. Each child is assigned a rating value given in the integer array ratings. You are giving candies to these children subjected to the following requirements: . | Each child must have at least one candy. | Children with a higher rating get more candies than their neighbors. Return the minimum number of candies you need to have to distribute the candies to the children | . Examples . Input: ratings = [1, 0, 2] –&amp;gt; 5 Explanation: The first, second, and third child can be given 2, 1, and 2 candies respectively. Input: ratings = [1, 2, 2] –&amp;gt; 4 Explanation: The first, second and third child can be given 1, 2, and 1 candies respectively as it satisfies the above conditions. Solution 1: Two Pass Array Construction . There are two conditions on each of the childrens&#39; candy amounts: One from the left, and one from the right. To solve the problem, we use two passes: one to ensure that the candy distribution satisfies the minimum demand from the left, and one to ensure that the candy distribution satisfies the minimum demand from the right (while also satisfying the left side&#39;s requirements). The algorithm has three steps: . | Create a new array candies with the same length as ratings and set candies[0]=1 | Iterate through ratings and candies from the left: if ratings[i] &amp;gt; ratings[i-1] then candies[i] = candies[i-1] + 1 | Iterate through ratings and candies from the right: if ratings[i] &amp;gt; ratings[i+1] then candies[i] = std::max(candies[i], candies[i+1]+1) Coding this up, we get the following solution: class Solution{ public: int candy(std::vector&amp;lt;int&amp;gt;&amp;amp; ratings) { int n = ratings.size(); int candies[n]; candies[0] = 1; for(int i = 1; i &amp;lt; n; i++){ if(ratings[i-1] &amp;lt; ratings[i]) candies[i] = candies[i-1]+1; else candies[i] = 1; } int sum = candies[n-1]; for(int i = n-2; i &amp;gt;=0; i--){ if(ratings[i] &amp;gt; ratings[i+1]) candies[i] = std::max(candies[i], candies[i+1] + 1); sum += candies[i]; } return sum; } }; . | . Runtime Analysis: . | In this function, there are two loops, both of which perform n linear operations. The time complexity is O(n). | There is one array created with size n. The space complexity is O(n). | . Solution 2: One Pass Greedy Algorithm . We have a solution that uses linear space, but can we do better? How could we calculate the sum of all childrens&#39; candies at the same time? We can accomplish constant space complexity with streak tracking. To calculate the sum of all childrens&#39; candy, we initialize candy to n, as each child must have at least one candy. We iterate through ratings, comparing ratings[i] to ratings[i-1]. At each point, there are 3 cases: . | ratings[i] &amp;gt; ratings[i-1] : In this case, the candies allocated to child [i] will be one higher than the candies allocated to child [i-1]. Begin a count of increasing streaks, add the current streak to candy and increase the streak. | ratings[i] &amp;lt; ratings[i-1] : In this case, the candies allocated to child [i-1] must have been one higher than the candies allocated to child [i]. Because the last child in a downward streak always gets one candy, the second-last two candies, etc., we keep track of the streak of downward ratings, with knowledge that the minimum sum is the triangular number corresponding to the streak. | ratings[i] == ratings[i-1] : In this case, the candies allocated to child [i] can be 1, so we break out of our loop iteration and reset both downward and upward streaks. In each case, we check if the current streak can be continued before checking for other conditions. | . Because an upward streak of upstreak and a downward streak of downstreak would result in double counting at the child where the upward streak ends and the downward streak begins, we save upstreak and downstreak and subtract std::min(upstreak, downstreak) from candy after each downward streak. Translating this algorithm into code, we get the following solution: . class Solution { public: int candy(vector&amp;lt;int&amp;gt;&amp;amp; ratings) { int n = ratings.size(); int candy = n, i=1; while(i&amp;lt;n){ if(ratings[i] == ratings[i-1]){ i++; continue; } int upstreak = 0; while(i&amp;lt;n &amp;amp;&amp;amp; ratings[i] &amp;gt; ratings [i-1]){ peak++; candy += peak; i++; } int downstreak = 0; while(i&amp;lt;n &amp;amp;&amp;amp; ratings[i] &amp;lt; ratings[i-1]){ valley++; candy += valley; i++; } candy -= min(upstreak, downstreak); //Keep only the higher peak } return candy; } }; . Runtime Analysis . | In this solution, we iterate through ratings once, performing a constant time operation on each member. Therefore, the time complexity is O(n). | The only memory used is two temporary integers upstreak and downstreak. Therefore, the space complexity is O(1). | .",
"url": "/docs/note/Candy-(Peaks-and-Valleys)"
},"6": {
"doc":  "Gas Station",
"title": "Gas Station",
"content": "There are n gas stations along a circular route, where the amount of gas at the i&#39;th station is gas[i]. You have a car with an unlimited gas tank, and it costs cost[i] to travel from the ith station to its next i+1th station. You begin the journey with an empty tank, at one of the gas stations. Given two integer arrays gas and cost, return the starting gas station&#39;s index if you can travel around the circuit once in the clockwise direction (stopping at every station). Otherwise, return -1. (If there exists a solution, it is guaranteed to be unique.) . Examples . Input: gas = [1, 2, 3, 4, 5], cost = [3, 4, 5, 1, 2] Output: 3 Explanation: Beginning at index 3, we will have the following amounts of gas in the tank after arriving at each station: [3, 6, 4, 2, 0]. Because we always have a non-negative amount of gas, index 3 satisfies our conditions. Input: gas = [2, 3, 4], cost = [3, 4, 3] Output: -1 Explanation: Because it costs more to travel to every station than it is possible to obtain gas, no starting index will satisfy the conditions. Solution 1: Brute Force . It is possible to brute force this problem. We could try beginning our trip at each of the n stations, and do n calculations to determine whether the starting index is valid. This would take \\(O(n^2)\\) time. Solution 2: Stay Positive . This is a trick question. Any solution must involve a non-negative amount of gas in the tank at every single gas station the car visits. The key insight to this question is that any non-solution will have a negative amount of gas in the tank at some station along the way. Therefore, if we find that starting at a is a non-solution because we will have negative gas in the tank after leaving station b, then no starting index in the range [a, b] can be a solution, as starting there will provide equivalent or less gas when you eventually leave station b. By not considering these indices, we eliminate many redundant calculations. Putting our solution into code, we get something like this: . class Solution{ public: int canCompleteCircuit(vector&amp;lt;int&amp;gt;&amp;amp; gas, vector&amp;lt;int&amp;gt;&amp;amp; cost){ int total; int n = gas.size(); for(int i = 0; i &amp;lt; n;){ total = 0; for(int j = 0; j &amp;lt; n; ++j){ total += gas[(i+j) % n] - cost[(i+j) % n]; if(total &amp;lt; 0){ i += j+1; break; } if(j == (n-1)) return i; } } return -1; } } . Runtime Analysis: . | Using a greedy algorithm, we consider each starting index exactly once. Our solution has \\(O(n)\\) time complexity. | Space Complexity: \\(O(1)\\) | .",
"url": "/docs/note/Gas-Station"
},"7": {
"doc":  "Stochastic Processes (2024-1-17)",
"title": "Stochastic Processes (2024-1-17)",
"content": "Instructor: Benson Au website: stat.berkeley.edu/~bensonau/s24.150 bcourses, Edstem, Gradescope Optional discussion sections, see poll for times Hw0 is Gradescope review, HW1 is due Friday 2024-1-26 . Today . Probability Space, Random Variable . Probability Space: \\((\\Omega, TF, P)\\) (sample space, algebra of sets, function that assigns likelihoods), where the probability function \\(P\\) assigns probability on the space and sums to 1. Random Variable: some \\(X \\in \\Omega\\) . We study the distribution of X: \\(M_X(A) = P(X\\in A)\\). For &quot;nice&quot; sets \\(A \\subseteq \\mathbb{R}\\). If X is discrete (countably infinite, by the way), we can work with the probability mass function \\(P_X(x) = P(X=x)\\) for \\(x \\in \\mathbb{R}\\) . if \\(X\\) is continuous, work with the probability density function of X: \\(f_X(x)\\), such that \\(\\int_Af_X(x) dx = P(X\\in A)\\) . What about in general? CDF: \\(F_X(x) = P(X\\in x)\\) . Expectation . If \\(X\\) is discrete, \\(E[g(X)] = \\sum_x g(x)p_X(x)\\) or \\(E[g(x)] = \\int g(x) f_X(x) dx\\) . In general, if \\(X \\geq 0, E[X] = \\int_0^\\infty P(X&amp;gt;x)dx = \\int_0^\\infty P(X\\geq x) dx\\) . Stochastic Process . What is a stochastic process? \\(X: \\Omega -&amp;gt; \\mathbb{R}\\) . \\(X: \\Omega \\times T -&amp;gt; \\mathbb{R}\\), where Time is a function that can be discrete or continuous. \\(\\omega, t -&amp;gt; X_t(w)\\) . Let&#39;s say you have a time series \\(x_1, x_2, x_3, x_4...\\) . Basic question. What do the trajectories look like? . Distribution \\((Y_n)_{n=1}^\\infty\\) i.i.d mean \\(\\mu\\) and variance 1 . \\[X_n = \\frac{Y_1 + ... + Y_n}{n}, (X_n)_{n=1}\\infty\\] by LLN, all the trajectories here approach the mean \\(\\mu\\). The trajectory has a horizontal asymptote at the mean. What about a new trajectory (sequence)? . \\[\\sqrt{n}(x_n-\\mu) \\overset{d}{\\to} N(0, 1)\\] The difference from the moving average to the mean, when scaled by the square root of the number of proceses, approaches the normal distribution. (assuming that the starting variables have variance 1) . If \\(X_1... X_n, \\quad T = \\{1, n\\}\\) . understand the joint distribution . \\[u_{X_1...X_n}(A_1, ... A_n) = P(X_1\\in A_1, X_n \\in A_n)\\] in the case of independence, joint probabilities is the same as multiplying the individual probabilities. Remember: \\(P(A \\Cap B) = P(A)P(B\\) given \\(A)\\) . Note: $$P_{X given Y}(x given y) = P(X=x given Y = y) = \\frac{P_{x, y}(x, y)}{P_Y(y)} .",
"url": "/docs/note/Stochastic-Processes-(2024-1-17)"
},"8": {
"doc":  "Grouping Increases",
"title": "Grouping Increases",
"content": "You are given an array a of size n. You will do the following process to calculate your penalty: . | Split array \\(a\\) into two (possibly empty) subsequences \\(s\\) and \\(t\\) such that every element of \\(a\\) is either in \\(s\\) or \\(t\\). | For an array \\(b\\) of size \\(m\\), define the penalty \\(p(b)\\) of an array \\(b\\) as the number of indices \\(i\\)between 1 and \\(m-1\\) where \\(b_i &amp;lt; b_{i+1}\\) | The total penalty you will receive is \\(p(s) + p(t)\\). | . If you perform the above process optimally, find the minimum possible penalty you will reveive. a sequence a is a subsequence of a sequence b if a can be obtained from \\(b\\) by the deletion of several (possibly, zero or all) elements. Example . Some valid ways to split array a = [3, 1, 4, 1, 5] into (s, t) ([3, 4, 1, 5], [1]), ([1, 1],[3, 4, 5]), ([],[3, 1, 4, 1, 5]) while some invalid ways to split a are ([3, 4, 5], [1]), ([3, 1, 4, 1], [1, 5]), ([1, 3, 4], [5, 1]) . Input . Each input contains multiple test cases. the first line contains a single integer \\(t: (1 \\leq t \\leq 10^4)\\) – the number of test cases. The description of the test cases follows. The first line of each test case contains a single integer \\(n: (1\\leq n \\leq 2\\cdot 10^5)\\) – the size of the array \\(a\\). The second line contains \\(n\\) integers \\(a_1, a_2, ..., a_n\\) : the elements of the array \\(n\\). It is guaranteed that the sum of \\(n\\) over all test cases does not exceed \\(10^5\\). Output . For each test case, output a single integer representing the minimum possible penalty you will receive. Solution 1: . Any increasing subsequences in these subsequences will result in a penalty. Note that for both arrays, we care only about the back element at any given time, as it is the only element that could actually impact the score. Let the two back elements be \\(x\\) and \\(y\\), and without loss of generality let \\(x &amp;gt; y\\). In the case where the arrays are empty, let the back element \\(= \\infty\\). Let the current element from input be \\(a\\) . Because there are many binary choices, where one option is totally outclassed by another, we are inspired to use a greedy algorithm. Accordingly, we break the problem into three cases. Case 1: \\(x \\geq y \\geq a\\): In this case, we may insert \\(a\\) on top of \\(x\\) or \\(y\\), without incurring any penalty. Inserting on \\(x\\) will leave two elements \\((a, y)\\), inserting on \\(y\\) will leave two elements \\((x, a)\\). Given these two choices, it is always better to insert over \\(y\\), as \\((x, a)\\) always gives us more freedom to insert more elements without penalty. Case 2: \\(a \\geq x \\geq y\\): In this case, we may insert \\(a\\) on top of \\(x\\) or \\(y\\), incurring a penalty of 1 no matter what we do. Inserting on \\(x\\) will leave two elements \\((a, y)\\), inserting on \\(y\\) will leave two elements \\((x, a)\\). Given these two choices, it is always better to insert over \\(y\\), as \\((x, a)\\) always gives us more freedom to insert more elements without penalty. Case 3: \\(x &amp;gt; a &amp;gt; y\\): In this case, we may insert \\(a\\) on top of \\(x\\) or \\(y\\). We have the option of \\((x, a)\\) with penalty 1, or \\((a, y)\\) with penalty 0. Call the next item that is inserted into this pair that is not inserted over \\(a\\) to be \\(b\\). There are three subcases here: . (1) If the next item not inserted over a in this pair is \\(b &amp;gt; x\\), choice 1 will have cost you two penalty, choice 2 will have cost you 1 penalty, and the state of the arrays is now the same. (2) If the next item not inserted over a in this pair is \\(x &amp;gt; b &amp;gt; y\\), choice 1 will have cost you one penalty, choice 2 will have cost you one penalty, and the state of the arrays is now the same. (3) If the next item not inserted over a in this pair is \\(y &amp;gt; b\\), choice 1 will have cost you one penalty, choice 2 will have cost you 0 penalty, and the state of the arrays is now the same. In all cases, it is at least as good to insert \\(a\\) over the larger element \\(x\\) for no penalty. This gives us a pretty simple set of decisions to make in any situation. Let&#39;s code up this solution: . #include &quot;bits/stdc++.h&quot; using namespace std; int t; int main(){ cin &amp;gt;&amp;gt; t; while(t--){ int n; cin &amp;gt;&amp;gt; n; int bigger = INT_MAX; int smaller = INT_MAX; int current; int pen = 0; while(n--){ cin&amp;gt;&amp;gt;current; if(current &amp;lt;= smaller){ smaller = current; }else if(current &amp;gt; bigger){ smaller = current; pen++; }else{ bigger = current; } if(bigger &amp;lt; smaller){ std::swap(bigger, smaller); } } cout &amp;lt;&amp;lt; pen &amp;lt;&amp;lt; &quot;\\n&quot;; } return 0; } . Runtime Analysis: . This function iterates through the list one time, doing a constant number of calculations, the runtime is \\(O(n)\\).",
"url": "/docs/note/Grouping-Increases-(Partitioning)"
},"9": {
"doc":  "Algorithmic Economics (2024-1-19)",
"title": "Algorithmic Economics (2024-1-19)",
"content": "Announcements: . | Fedevico&#39;s office hours: Fridays 10-12:30 (509 Evans) | PS1 out on Monday | Scribe signup available | . Preliminary Notions . Let X be a set, and define a binary relation on X as a subset B of \\(X \\times X\\) . Ex: \\(X = \\{\\text{Mary, John, Carlos}\\}\\). Suppose Mary is older than Carlos, who is older than John. The binary relation &quot;is older than&quot; is {(Mary, Carlos), (Carlos, John), (Mary, John)} . Notation: Given a binary relation \\(B\\), we shall write \\(x B y\\) instead of \\((x, y) \\in B\\) . Ex: \\(\\supset\\) is a binary relation of a set \\(X\\). We write \\(X \\supset y\\) instead of \\((x, y) \\in \\supseteq\\) . Let \\(\\geq\\) be a binary relation of a set \\(X\\). Def: \\(\\geq\\) is complete s.t. \\(\\forall x, y \\in X, \\quad x \\geq y\\text{or} y \\geq x\\) (or both) . Def \\(\\geq\\) is transitive if \\(\\forall x, y, z \\in X, if x \\geq y,\\) and \\(y \\geq z \\implies x \\geq z\\). Antisymmetric if \\(\\forall x, y \\in X,x \\geq y, y \\geq x \\implies x = y\\) . Def: The indifference part of the binary relation is defined by \\(\\sim = \\{(x, y) : (x, y) \\in \\geq\\ \\text{and} (y, x) \\in \\geq\\}\\) . A binary order is called a weak order if it is a complete order and a transitive order. In this class, we call weak orders preference relations. Interpretations: If \\(\\geq\\) is the preference relation of an agent then \\(X \\geq y\\) means that the agent is happy choosing \\(x\\) out of the set \\(\\{x, y\\}\\). And \\(x &amp;gt; y\\) means that the agent would exclusively choose \\(x\\) for \\(\\{x, y\\}\\). Def: A preference relation that is also antisymmetric is called a strict preference. Actually antisymmetry and completeness implies exclusivity (no two elements have the same place in the order) . Given a function \\(u: X \\to R\\), we may define a binary relation \\(\\geq\\) by \\(x \\geq y\\) if and only if \\(u(x) \\geq u(y)\\). Exercise: Prove that \\(\\geq\\) defined in this way is a preference relation. In this case, we say that u represents \\(\\geq\\), and that u is a utility representation of \\(\\geq\\). And, \\(x \\sim y\\) iff \\(u(x) = u(y)\\). First Economic Problem . Object Allocation . Model primitives: . A finite (nonempty) set \\(A\\) of agents. A finite (nonempty) set \\(O\\) of objects. A symbol \\(\\empty\\) representning the outside option. Each student \\(i \\in A\\) is endowed with a strict prefefrence \\(\\succeq\\) over \\(O \\cup\\{\\empty\\}\\). Ineffieient if slack in system: Stable matching .",
"url": "/docs/note/Algorithmic-Economics-(2024-1-19)"
},"10": {
"doc":  "01 Tree",
"title": "01 Tree",
"content": "There is an edge-weighted complete binary tree with n leaves. A complete binary tree is defined as a tree where every non-leaf vertex has exactly 2 children. For each non-leaf vertex, we label one of its children as the left child, and the other as the right child. The binary tree has a very strange property. For every non-leaf vertex, one of the edges to its children has weight 0 while the other edge has weight 1. Note that the edge with weight 0 can be connected to either its left or right child. You forgot what the tree looks like, but luckily, you still remember some information about the leaves in the form of an array a of size n. For each i from 1 to n, \\(a_i\\) represents the distance from the root to the i-th leaf in dfs order. Determine whether there exists a complete binary tree which satisfies array a. The dfs order of the leaves traverses them in left to right order recursively. The distance from vertex u to vertex v is defined as the sum of weights of the edges on the path from vertex u to vertex v. Example: . Input: . 2 5 2 1 0 1 1 5 1 0 2 1 3 . Output: . YES NO . Solution . TBH i didn&#39;t code this but roughly the solution goes like this: . Given an array of these bottom leaves, note that we can always replace the highest value leaf and a neighbor that has value one less with just the neighbor. This is equivalent to taking two leaves and replacing them with their parent to form a new valid complete binary tree. Having done this, we need to somehow radiate outward, replacing children with their parents until we are left with just one node in O(n) time. I&#39;m not sure how to accomplish this, but the below code apparently does it. #include&amp;lt;bits/stdc++.h&amp;gt; using namespace std; const int MAXN = 200005; int n; int a[MAXN]; int prv[MAXN],nxt[MAXN]; bool in[MAXN]; bool good(int i) { if (i &amp;lt; 1 || i &amp;gt; n) { return 0; } return a[prv[i]] == a[i] - 1 || a[nxt[i]] == a[i] - 1; } int main(){ ios::sync_with_stdio(0), cin.tie(0); int t; cin &amp;gt;&amp;gt; t; while (t--) { cin &amp;gt;&amp;gt; n; priority_queue&amp;lt;pair&amp;lt;int, int&amp;gt;&amp;gt; pq; for (int i = 1; i &amp;lt;= n; i++) { prv[i] = i - 1; nxt[i] = i + 1; in[i] = 0; cin &amp;gt;&amp;gt; a[i]; } a[n + 1] = a[0] = -2; for (int i = 1; i &amp;lt;= n; i++) { if (good(i)) { in[i] = 1; pq.push({a[i], i}); } } while (!pq.empty()) { auto [_, i] = pq.top(); pq.pop(); nxt[prv[i]] = nxt[i]; prv[nxt[i]] = prv[i]; if (!in[prv[i]] &amp;amp;&amp;amp; good(prv[i])) { in[prv[i]]=1; pq.push({a[prv[i]], prv[i]}); } if (!in[nxt[i]] &amp;amp;&amp;amp; good(nxt[i])) { in[nxt[i]]=1; pq.push({a[nxt[i]], nxt[i]}); } } int mn = n, bad = 0; for (int i = 1; i &amp;lt;= n; i++) { bad += !in[i]; mn = min(a[i], mn); } if (bad == 1 &amp;amp;&amp;amp; mn == 0) { cout &amp;lt;&amp;lt; &quot;YES\\n&quot;; } else { cout &amp;lt;&amp;lt; &quot;NO\\n&quot;; } } } . Runtime analysis: O(n log n) .",
"url": "/docs/note/01-Tree"
},"11": {
"doc":  "Karen and Coffee",
"title": "Karen and Coffee",
"content": "You know n coffee recipes, and the i-th recipe suggests that coffee should be brewed between $l_i$ and $r_i$ degrees, inclusive, to achieve the optimal taste. Karen thinks that a temperature is admissible if at least k recipes recommend it. If Karen asks q questions, each one supposing she only wants to prepare coffee with a temperature between a and b, inclusive, can you tell her how many admissible integer temperatures fall within the range? . Input . The first line of input contains three integers n, k $(1\\leq k \\leq n \\leq 200000)$, and q $(\\leq k \\leq n \\leq 200000)$, the number of recipes, the minimum number of recipes a certain temperature must be recommended by to be admissible, and the number of questions Karen has, respectively. The next n lines describe the recipes. Specifically, the i-th line among these contains two integers $l_i$ and $r_i$ $(1 \\leq l_i \\leq r_i \\leq 200000)$, describing that the i-th recipe suggests that the coffee be brewed between $l_i$ and $r_i$ degrees, inclusive. the next q lines describe the questions. Each of these lines contains a and b, $(1\\leq a \\leq b \\leq 200000)$, describing that she wants to know the number of admissible integer temperatures between a and b degrees, inclusive. Output . For each question, output a single integer on a line by itself, the number of admissible integer temperatures between a and b degrees, inclusive. Example 1: . Input 3 2 4 91 94 92 97 97 99 92 94 93 97 95 96 90 100 ____________ Output 3304 . Example 2: . Input 2 1 1 1 1 200000 200000 90 100 ____________ Output 0 . Solution: Prefix Sum . To solve this problem, we use prefix sums. Because there are up to 200000 queries q, it is important that we do as much computation as possible beforehand. To this end, we construct a list of values ps[200000], such that ps[i] represents the total number of temperatures [1, i) that satisfy at least k of the conditions. We can make two passes through n to construct this array, one that fills ps with the number of conditions that the temperature corresponding to each element fulfills, and one that sums over these values to create our prefix sum. Afterwards, we can iterate through ps, subracting ps[start] from ps[end] to find the total number of temperatures in the range satisfying at least k of the conditions. Here&#39;s the implementation of this logic: . int main(){ int n, k, q; cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; k &amp;gt;&amp;gt; q; int ps[200001] = {0}; //set boundaries where we start and end satisfying a condition while(n--){ int tstart, tend; cin &amp;gt;&amp;gt; tstart &amp;gt;&amp;gt; tend; ps[tstart]++; ps[tend+1]--; } int curr = 0; //the number of valid temperatures (including the current) int totalSatisfying = 0; //fill out the prefix sum for(int i = 0; i &amp;lt; 200001; ++i){ curr += ps[i]; if(curr &amp;gt;= k){ totalSatisfying++; } ps[i] = totalSatisfying; } while(q--){ int tstart, tend; cin &amp;gt;&amp;gt; tstart &amp;gt;&amp;gt; tend; cout &amp;gt;&amp;gt; ps[tend] - ps[tstart-1] &amp;gt;&amp;gt; &quot;\\n&quot;; } return 0; } . Runtime Analysis: . Setting boundaries: O(n) Filling out prefix sum: O(200000) Calculating answers: O(q) Our total runtime is O(200000 + n + q), for a high fixed cost but well-scaling solution. Space complexity is O(200000), which is also high-inital but well scaled cost. The main idea behind this problem, and most prefix sum problems in general, is to precompute as much as possible so the linear cost of computation is not passed onto the q queries that it is possible to get.",
"url": "/docs/note/Karen-and-Coffee"
},"12": {
"doc":  "Remove Duplicates From Sorted Array",
"title": "Remove Duplicates From Sorted Array",
"content": "Given an integer array nums, sorted in non-decreasing order, remove some duplicates in-place such that each unique element appears at most twice. The relative order of the elements should be kept the same. Place your answer list containing k elements in the first k elements of nums, and return k. Input/Output . Example 1 . Input: nums = [1, 1, 1, 2, 2, 3] Output: 5, nums = [1, 1, 2, 2, 3, _] . Example 2 . Input: nums = [0, 0, 1, 1, 1, 1, 2, 3, 3] Output: 7, nums = [0, 0, 1, 1, 2, 3, 3, _, _] . Solution 1: Cache Previous Value . The path to solving this problem involves iterating through nums and overwriting some prior values at an offset that increments whenever we encounter a value that should be discarded. (We discard any indices who have two equal values prior). This way, we will only ever be writing to the first n values that correspond to the final value of nums. However, this solution runs into problems if overwriting one of the previous values changes the evaluation of the next value. To track the current index we are evaluating and the index that we will overwrite, we use two local variables, left and right. To make sure that we don&#39;t change the evaluation of a future index, we will pre-evaluate whether the next index should be kept or discarded before moving past the current value of right. In the end, we return left as the number of non-discarded elements in the array. Here&#39;s one implementation the above logic: . class Solution{ public: int removeDuplicates(vector&amp;lt;int&amp;gt;&amp;amp; nums) { if(nums.size() &amp;lt;= 2)return nums.size(); //The position in unique_list we&#39;re inserting into int left = 2; //The position in raw_list we&#39;re evaluating int right = 2; //Do we include (right-1)? or not int include_prev = 1; if(nums[0] == nums[1] &amp;amp;&amp;amp; nums[2] == nums[0]){ include_prev = 0; } right++; while(right &amp;lt; nums.size()){ //Is the current location unnecessary? if so, increment right but not left if(nums[right-2] == nums[right-1] &amp;amp;&amp;amp; nums[right] == nums[right-2]){ if(include_prev){ nums[left] = nums[right-1]; left++; } include_prev = 0; }else{ if(include_prev){ nums[left] = nums[right-1]; left++; } include_prev = 1; } right++; } if(include_prev){ nums[left] = nums[right-1]; left++; } return left; } }; . Solution 2: No Lookahead . Solution 1 actually does some unnecessary calculations. The reason for precomputing whether right should be kept or ignored was because this evaluation, nums[right] == nums[right-1] || nums[right] == nums[right-2], where all indices have their original values, would evaluate to something different in the case we overwrote nums[right-2] with nums[right-1] in an earlier iteration. A much better way to approach this solution is to look back from left, to see if we already have two of the values equal to nums[right] in the list to return that we are building. This avoids any caching of values and results in much simpler code. Implementing this solution, we get the following code: . class Solution { public: int removeDuplicates(vector&amp;lt;int&amp;gt;&amp;amp; nums){ int n = nums.size(); if(n &amp;lt; 3) return n; int left = 2; for(int right = 2; right &amp;lt; n; ++right){ if(nums[right] != nums[left-2]){ nums[left] = nums[right]; left++; } } return left; } }; .",
"url": "/docs/note/Remove-Duplicates-From-Sorted-Array"
},"13": {
"doc":  "Permutations",
"title": "Permutations",
"content": "Permutations . Given an array nums of distinct integers, return all the possible permutations. You can return the answer in any order. Example: . \\( [1, 2, 3] \\to [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]]\\) . Solution 1: Naive . We can do a DFS and at each node, pass the current state of the list down to all children by value. This will create a copy of the list local to that child only, which can be modified and then passed to the children&#39;s children. Code: . class Solution { public: vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; permute(vector&amp;lt;int&amp;gt;&amp;amp; nums) { unordered_set&amp;lt;int&amp;gt; seen; vector&amp;lt;int&amp;gt; currentList; return permuteWithSet(nums, currentList, seen); } vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; permuteWithSet(vector&amp;lt;int&amp;gt;&amp;amp; nums, vector&amp;lt;int&amp;gt; currentList, unordered_set&amp;lt;int&amp;gt;&amp;amp; seen) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; res; if (currentList.size() == nums.size()) { res.push_back(currentList); return res; } for (int i : nums) { if (seen.find(i) != seen.end()) continue; seen.insert(i); currentList.push_back(i); for (vector&amp;lt;int&amp;gt; j : permuteWithSet(nums, currentList, seen)) { res.push_back(j); } seen.erase(i); currentList.erase(currentList.end() - 1); } return res; } }; . Time Complexity: O(n!) calls, and because we pass by value, each of the n! calls has to copy and destroy n spaces in memory . Space Complexity: O(n!) space, and because we pass by value, there&#39;s additional overhead in the function frames. Solution 2: Pass by Reference . In this solution, we take a different approach. For each array in nums, insert it into all the positions it could possibly go in the current array we have built. Then, return all the possible lists created at the end. We pass by reference, and return only on the base case. Here is the code: . class Solution { public: vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; permute(vector&amp;lt;int&amp;gt;&amp;amp; nums) { vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt; res; vector&amp;lt;int&amp;gt; curr; DFS(res, nums, 0, curr); return res; } void DFS(vector&amp;lt;vector&amp;lt;int&amp;gt;&amp;gt;&amp;amp; res, vector&amp;lt;int&amp;gt;&amp;amp; nums, int index, vector&amp;lt;int&amp;gt;&amp;amp; curr){ if(index == nums.size()){ res.push_back(curr); return; } for(int i = 0; i &amp;lt;= curr.size(); i++){ curr.insert(curr.begin() + i, nums[index]); DFS(res, nums, index+1, curr); curr.erase(curr.begin() + i); } return; } }; . Time Complexity: O(n!) calls but save operations in the call stack . Space Complexity: O(n!) space, but save a lot of space in the call stacks.",
"url": "/docs/note/Permutations"
},"14": {
"doc":  "Diameter Of Binary Tree",
"title": "Diameter Of Binary Tree",
"content": "Diameter Of a Binary Tree . Given the root of a binary tree, return the length of the diameter of the tree. The diameter of a binary tree is the length of the longes path between any two nodes in a tree. This path may or may not pass through the root. Examples: . Example 1: . Input: root = [1, 2, 3, 4, 5] . Output: 3 . Example 2: . Input: root = [1, 2] . Output: 1 . here trees are represented in array in a bfs order where all members of layer n are listed before all members of layer n+1 . Solution 1: Naive Recursive . We implement a recursive solution where the only parameter is the root node. Note that in our main funciton, we need to track the longest diameter of the left child and the longest diameter of the right child. To help with our solution, we implement two helper functions which are also recursive. Implementation: . class Solution{ private: int longestLeftPath(TreeNode* root){ if(root == nullptr || root-&amp;gt;left == nullptr){ return 0; } return 1 + max(longestLeftPath(root-&amp;gt;left), longestRightPath(root-&amp;gt;right)); } int longestRightPath(TreeNode* root){ if(root == nullptr || root-&amp;gt;right == nullptr){ return 0; } return 1 + max(longestLeftPath(root-&amp;gt;left), longestRightPath(root-&amp;gt;right)); } public: int diameterOfBinaryTree(TreeNode* root){ if(root == nullptr) return 0; return max(longestLeftPath(root) + longestRightPath(root), max(diameterOfBinaryTree(root-&amp;gt;left), diameterOfBinarytree(root-&amp;gt;right)) ); } } . Complexity analysis: . Time Complexity: . The time complexity of longestLeftPath and longestRightPath is \\(O(n)\\) because we do \\(o(1)\\) work per call and have a max of n calls. The time complexity of diameterOfBinaryTree is \\(O(n)\\) time for the longestLeftPath and longestRightPath calls and because of recursion, these calls can happen a maximum of \\(n\\) times. So the overall time complexity is \\(O(n^2)\\) due to our helper functions. The overall space complexity is \\(O(n^2)\\) because recursive calls happen a maximum of \\(n^2\\) times in total. Solution 2: Updating value while recursing . To save runtime, we combine our previous functions into one recursive function. However, we need some form of memory, because it may be the case that the left height + the right height is less than the diameter of either the left subtree or the right subtree alone. Therefore, we will carry our best previous diameter within a pointer diameter and update it whenever we have a new greatest diameter. Implementation: . class Solution{ private: //height measures the distance from the root to a leaf int heightWithDia(TreeNode* root, int&amp;amp; diameter){ if(root=nullptr) return 0; int lh = heightWithDia(TreeNode* root-&amp;gt;left, diameter); int rh = heightWithDia(TreeNode* root-&amp;gt;right, diameter); //crucial to have a max here, because in some cases lh will be 0 or 1 while lh or rh of the children is high. diameter = max(diameter, lh + rh); return max(lh + 1, rh + 1); } public: int diameterOfBinaryTree(TreeNode* root){ int dia = 0; heightWithDia(root, dia); return dia; } } . Complexity Analysis . Time Complexity: . The time complexity of heightWithDia is \\(O(n)\\). We do \\(O(1)\\) work a maximum of \\(n\\) times. The overall time and space complexity is \\(O(n)\\) because all we have to do is initialize and return a variable dia.",
"url": "/docs/note/Diameter-Of-Binary-Tree"
},"15": {
"doc":  "Template",
"title": "Template",
"content": "Template . problem statement . Examples . $$latex$$(use ) explanation . Solution 1: . Solution 2: . TODO: is there a way to do right-aligned comments in code sections? nicer lc style formatting for code blocks make a real homepage proving every theorem in the matrix cookbook (no bitchmode) . Feb 5: CS177 homework(finish by 9 pm) CS189 homework(finish by 12 am) .",
"url": "/docs/note/Template"
},"16": {
"doc":  "Test",
"title": "Test",
"content": "\\(test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}\\) . \\(test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}\\) . \\[test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}\\] Testing inline math: \\(test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}\\) . Parentheses inline: \\(test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}\\) . $test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}$ . $$test \\quad x^2 \\quad \\frac{1}{test} \\frac{1}{\\text{test}}$$ . \\[[1, 4, 5], [1, 3, 4], [2, 6]\\] . [[1, 4, 5], [1, 3, 4], [2, 6]] . \\[[ test1, test1]\\] \\[\\[ test2, test2 \\]\\] \\( [test3, test3 ]\\) . \\( [test4, test4 ]\\) .",
"url": "/docs/note/Test"
}
}